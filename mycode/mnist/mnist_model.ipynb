{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andmholm/Backdoor/backdoor_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data needs to be in Tensor format and must be normalized to make computing the gradient faster, and optimization quicker\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,)), ])\n",
    "\n",
    "batch_size = 128 # amount of examples we see in data before we update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the transformer initialized, we load, shuffle, then transform the data using DataLoader class\n",
    "\n",
    "# training data\n",
    "trainset = torchvision.datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "# testing data\n",
    "testset = torchvision.datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "\n",
    "# loading training & testing data\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of images: torch.Size([64, 1, 28, 28])\n",
      "shape of labels: torch.Size([64])\n",
      "example imahe\n",
      "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242,  0.3649,  0.5431,  0.5431,  0.5431,\n",
      "           0.5431,  0.2758, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.3606,  0.9250,  1.0268,\n",
      "           1.5232,  2.4015,  2.4015,  2.7197,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.6942,  2.4015, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.0424,  2.5033,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.3733,  1.6123,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  2.1214,  1.7650,  1.7650,  1.7650,  1.1923,\n",
      "           1.7650,  0.8104,  0.4031, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242,  0.4286,  2.7960,  2.7960,  2.7960,  2.7706,\n",
      "           1.0777, -0.0806, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242,  0.4922,  2.6815,  2.7960,  2.7960,  2.7960,  2.5415,\n",
      "           1.5741,  0.2886, -0.2078, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.4795,  2.6178,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  1.3959, -0.2078, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860,\n",
      "           2.1469,  2.7960,  2.7960,  2.7960,  2.7324,  2.5924,  2.5924,\n",
      "           2.6687,  2.7960,  2.7960,  2.0578, -0.2715, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3606,\n",
      "           2.5287,  2.7960,  2.4142,  0.7468,  0.3395, -0.4242, -0.4242,\n",
      "           0.0085,  2.0832,  2.7960,  2.7960,  1.9560, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "           0.8104,  1.1923, -0.0551, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.3606,  1.9432,  2.7960,  2.7324,  0.3904, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242,  1.5868,  2.7960,  2.7960,  1.2941, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242,  0.3395,  2.7960,  2.7960,  1.9687, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.2333, -0.0806, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242,  1.4468,  2.7960,  2.7960,  1.9687, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242,  2.7069,  2.7069,  2.6815,\n",
      "           2.6815,  2.2360,  0.6577, -0.0678, -0.1951, -0.4242, -0.4242,\n",
      "          -0.4242, -0.1187,  2.2869,  2.7960,  2.7706,  0.5431, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242,  2.8088,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960,  2.7960,  2.4524,  1.7778,  1.7778,\n",
      "           1.7778,  2.2996,  2.7960,  2.7960,  2.0960, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242,  0.3268,  1.4850,  2.0832,\n",
      "           2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
      "           2.7960,  2.7960,  2.7960,  2.2996, -0.1187, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3988,\n",
      "          -0.3606,  0.0849,  1.0141,  1.0141,  1.4723,  2.2996,  1.3068,\n",
      "           2.3887,  1.6759,  0.6959, -0.3860, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 64 images (each batch) of 1 channel of 28x28 pixels\n",
    "print(f\"shape of images: {images.shape}\")\n",
    "# 64 labels\n",
    "print(f\"shape of labels: {labels.shape}\")\n",
    "\n",
    "print(f'example imahe\\n{images[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d20332190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying the image\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 4, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(f.relu(self.conv1(x)))\n",
    "        x = self.pool(f.relu(self.conv2(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc2(x)\n",
    "        out = f.log_softmax(x, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, loss_fn, batch_size=32, epochs=3):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net.to(device)\n",
    "    net.train() # indicate to layers they're being trained on\n",
    "    n = len(trainloader.dataset)\n",
    "\n",
    "    # iterate for n epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trained = 0\n",
    "\n",
    "        # iterate and train on each batch\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get data, predict data, find loss, update & take a step to optimize on next iteration\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            trained += batch_size\n",
    "\n",
    "    # display info every half of epoch\n",
    "            if not (i + 1) % (len(trainloader) // 2):\n",
    "                print(f\"epoch: {epoch + 1} trained: {trained if trained < n else n}/{n} loss: {loss.item()}\")\n",
    "        print(f\"epoch complete trained: {n}/{n} loss: {loss.item()}\")\n",
    "    print(\"training complete\")\n",
    "    net.to('cpu')\n",
    "    del device\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "optimizer = torch.optim.Adadelta(net.parameters(), lr=1)\n",
    "loss = f.nll_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(net, testloader, loss_fn):\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    n = len(testloader.dataset)\n",
    "\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        loss += loss_fn(outputs, labels)\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        if i == 0:\n",
    "            print(pred.size())\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()    \n",
    "    loss /= n\n",
    "\n",
    "    print(f\"avg loss: {loss} acc: {correct / n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 trained: 30016/60000 loss: 0.1954796016216278\n",
      "epoch: 1 trained: 60000/60000 loss: 0.06426367908716202\n",
      "epoch complete trained: 60000/60000 loss: 0.06426367908716202\n",
      "epoch: 2 trained: 30016/60000 loss: 0.008466465398669243\n",
      "epoch: 2 trained: 60000/60000 loss: 0.001839307602494955\n",
      "epoch complete trained: 60000/60000 loss: 0.001839307602494955\n",
      "epoch: 3 trained: 30016/60000 loss: 0.013173606246709824\n",
      "epoch: 3 trained: 60000/60000 loss: 0.07999547570943832\n",
      "epoch complete trained: 60000/60000 loss: 0.07999547570943832\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "train(net, trainloader, optimizer, loss, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "avg loss: 0.0006581118796020746 acc: 0.9874\n"
     ]
    }
   ],
   "source": [
    "test(net, testloader, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"models/mnist_net.pth\") # saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net() # init class of model\n",
    "net.load_state_dict(torch.load(\"models/mnist_net.pth\")) # load parameters to model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('backdoor_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91f5593089a39d29b7be4682cd00d4ab41e1e0aeef21da075bd20affb91499cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
